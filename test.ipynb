{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from datasets import load_metric\r\n",
    "from fastcore.foundation import L\r\n",
    "\r\n",
    "metric = load_metric(\"triple_metric.py\")\r\n",
    "pred = torch.load(\"preds\")\r\n",
    "references = torch.load(\"golds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_f1(pred,references,id2label=None,thres=0.62):\r\n",
    "    predictions = list(L(pred).map(lambda x:L(x).filter(lambda y:y[3]>thres and y[1]<=y[2]).map(lambda z:z[:3])))\r\n",
    "    m = metric.compute(predictions=predictions,references=references,id2label=id2label,digits=6)\r\n",
    "    return m\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thres 0.3 \t micro_avg Score(f1=0.634619, precision=0.582387, recall=0.697143)\n",
      "thres 0.31 \t micro_avg Score(f1=0.634897, precision=0.58365, recall=0.69601)\n",
      "thres 0.32 \t micro_avg Score(f1=0.635414, precision=0.585186, recall=0.695074)\n",
      "thres 0.33 \t micro_avg Score(f1=0.636036, precision=0.586627, recall=0.694532)\n",
      "thres 0.34 \t micro_avg Score(f1=0.636462, precision=0.587919, recall=0.693744)\n",
      "thres 0.36 \t micro_avg Score(f1=0.636782, precision=0.590429, recall=0.691034)\n",
      "thres 0.37 \t micro_avg Score(f1=0.637129, precision=0.591819, recall=0.689951)\n",
      "thres 0.38 \t micro_avg Score(f1=0.637545, precision=0.593413, recall=0.688768)\n",
      "thres 0.39 \t micro_avg Score(f1=0.637816, precision=0.594801, recall=0.687537)\n",
      "thres 0.4 \t micro_avg Score(f1=0.638075, precision=0.596141, recall=0.686355)\n",
      "thres 0.41 \t micro_avg Score(f1=0.638162, precision=0.597413, recall=0.684877)\n",
      "thres 0.42 \t micro_avg Score(f1=0.63844, precision=0.598766, recall=0.683744)\n",
      "thres 0.43 \t micro_avg Score(f1=0.638755, precision=0.600347, recall=0.682414)\n",
      "thres 0.44 \t micro_avg Score(f1=0.638926, precision=0.601645, recall=0.681133)\n",
      "thres 0.45 \t micro_avg Score(f1=0.63957, precision=0.603523, recall=0.680197)\n",
      "thres 0.46 \t micro_avg Score(f1=0.64026, precision=0.605534, recall=0.679212)\n",
      "thres 0.47 \t micro_avg Score(f1=0.6403, precision=0.606982, recall=0.677488)\n",
      "thres 0.48 \t micro_avg Score(f1=0.640585, precision=0.608767, recall=0.675911)\n",
      "thres 0.49 \t micro_avg Score(f1=0.641002, precision=0.61089, recall=0.674236)\n",
      "thres 0.5 \t micro_avg Score(f1=0.641404, precision=0.613087, recall=0.672463)\n",
      "thres 0.51 \t micro_avg Score(f1=0.641916, precision=0.615468, recall=0.670739)\n",
      "thres 0.55 \t micro_avg Score(f1=0.642035, precision=0.622743, recall=0.662562)\n",
      "thres 0.62 \t micro_avg Score(f1=0.642146, precision=0.638039, recall=0.646305)\n"
     ]
    }
   ],
   "source": [
    "max_f1 = 0.0\r\n",
    "id2label = dict(zip(range(9),[\"bod\", \"dep\", \"dis\", \"dru\", \"equ\", \"ite\", \"mic\", \"pro\", \"sym\"]))\r\n",
    "for i in range(30,95):\r\n",
    "    thres = i/100\r\n",
    "    m = find_best_f1(pred,references,id2label=None,thres=thres)\r\n",
    "    if m[\"micro_avg\"].f1>=max_f1:\r\n",
    "        max_f1 = m[\"micro_avg\"].f1\r\n",
    "        print(\"thres\",thres,\"\\t\",\"micro_avg\",m[\"micro_avg\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "086317466957d500e1e3add5d1080e4cde135e955220d9fc98fd7fe59df8a909"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}